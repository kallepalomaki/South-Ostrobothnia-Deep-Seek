{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8927e13b17a54352a84f62e23681ce1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21197ff61a2a41608ec22e1c5a652a58",
              "IPY_MODEL_aa0d03affee44739a7254fa4942656bb",
              "IPY_MODEL_31c32434249749139d029f184576f0c7"
            ],
            "layout": "IPY_MODEL_2f1bee6cb65c4d8482a626f225074501"
          }
        },
        "21197ff61a2a41608ec22e1c5a652a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e5f1b63655a4ec7b479f4634067cdd3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5b877b99c03f44659ec8ad6079d07801",
            "value": "Map:‚Äá100%"
          }
        },
        "aa0d03affee44739a7254fa4942656bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b944732af3004ccfaef4a2691cd82495",
            "max": 306,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_036eac72cb4944dda654d0c5eb0993b5",
            "value": 306
          }
        },
        "31c32434249749139d029f184576f0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed89eb8130784397903a65fa0b6da84e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cd831f04378f4eb1be9ce2b7c3047f86",
            "value": "‚Äá306/306‚Äá[00:00&lt;00:00,‚Äá12620.15‚Äáexamples/s]"
          }
        },
        "2f1bee6cb65c4d8482a626f225074501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e5f1b63655a4ec7b479f4634067cdd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b877b99c03f44659ec8ad6079d07801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b944732af3004ccfaef4a2691cd82495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "036eac72cb4944dda654d0c5eb0993b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed89eb8130784397903a65fa0b6da84e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd831f04378f4eb1be9ce2b7c3047f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e6ee0b6599d47d8b97bd05426328951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd19162a2ebe4e3f83302e84925a4dd3",
              "IPY_MODEL_524d72b59bb54fa0b9637744205f3a11",
              "IPY_MODEL_ef700c51b4474237a79c9d2caaac6cc3"
            ],
            "layout": "IPY_MODEL_81ca3194b6b9434e913210e8100af975"
          }
        },
        "fd19162a2ebe4e3f83302e84925a4dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1acfd56ea16c4e68977494991b4f949b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bd699d3d83e14b8f8529370807169f05",
            "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "524d72b59bb54fa0b9637744205f3a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1db372d15294400cb7442d6500ce1d2c",
            "max": 306,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f201bf1c46d4e639eba748ab8e0870f",
            "value": 306
          }
        },
        "ef700c51b4474237a79c9d2caaac6cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf0d8e012ef42cf844c8b633964aef6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dcf65fa8af5d4673ab201fee64f01068",
            "value": "‚Äá306/306‚Äá[00:02&lt;00:00,‚Äá167.61‚Äáexamples/s]"
          }
        },
        "81ca3194b6b9434e913210e8100af975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1acfd56ea16c4e68977494991b4f949b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd699d3d83e14b8f8529370807169f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1db372d15294400cb7442d6500ce1d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f201bf1c46d4e639eba748ab8e0870f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bf0d8e012ef42cf844c8b633964aef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcf65fa8af5d4673ab201fee64f01068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kallepalomaki/South-Ostrobothnia-Deep-Seek/blob/main/deep_seek_southob_blog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This a google Colab notebook based on Data camp Deep Seek fine tuning tutorial https://www.datacamp.com/tutorial/fine-tuning-deepseek-r1-reasoning-model which I have adapted to for translating standard Finnish to South Osthrobothnian dialect. Fine tuning data is done in two passes firstly a bit over 300 standard Finnish and South Osthrobothnian dialect sentence pairs and second on bit over 2000 standard Finnish South Osthrobothnia word pairs. South Osthrobothnian sentences are taken from Pekka Pohjanp√§√§'s blog: http://pohopekka.blogspot.com/\" I'm not sharing the sentence pairs but Standard Finnish that correspond the blog text. Blog text is indexed by sentence order so that standard Finnish sentences can be matched. I also share the vocabulary. Shared data is placeded at directory data.\n",
        "Not that the blog is Copyrighted material and I haven't reached copyright holder. Therfore I provide only a download function. Use at your own responsibility."
      ],
      "metadata": {
        "id": "XmdmEWx70sQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install unsloth\n",
        "!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T07:22:13.068851Z",
          "iopub.execute_input": "2025-03-15T07:22:13.069244Z",
          "iopub.status.idle": "2025-03-15T07:25:24.544624Z",
          "shell.execute_reply.started": "2025-03-15T07:22:13.069203Z",
          "shell.execute_reply": "2025-03-15T07:25:24.543408Z"
        },
        "id": "ZcTI6dtVSlVH"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N7yA6AXtVrw",
        "outputId": "19101db0-6ead-4358-a003-2ef9ad5db4eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.11/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Directory settings. Adapt the as needed. Secrets are needed for huggingface and wandb tokens. Datadir is needed for storing General Finnish - South Ostrobotnian vocabulary data in file vocabulary_deep_seek_format.json and dialect sentence indices against standard Finnish sentences file in standard_finnish_sentences.json. I'm using google colab, and therefore directories point to google drive."
      ],
      "metadata": {
        "id": "nES17CfOzY_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SECRETS_DIR = \"/content/drive/My Drive/secrets\"\n",
        "DATA_DIR = \"/content/drive/My Drive/data\""
      ],
      "metadata": {
        "id": "mOr0dyQ-nRFK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "secret_file_path = SECRETS_DIR+'/huggingfacetoken.key'\n",
        "with open(secret_file_path) as f:\n",
        "  hf_token=f.read().strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O7nKpcBU6rm",
        "outputId": "f5595065-8524-4ce8-e29b-d3eecbbec64d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "secret_file_path = SECRETS_DIR+'/wandb.key'\n",
        "\n",
        "with open(secret_file_path) as f:\n",
        "  wb_token=f.read().strip()"
      ],
      "metadata": {
        "id": "yDscdP60WmxU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(hf_token)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T07:25:24.546101Z",
          "iopub.execute_input": "2025-03-15T07:25:24.546462Z",
          "iopub.status.idle": "2025-03-15T07:25:25.639298Z",
          "shell.execute_reply.started": "2025-03-15T07:25:24.546426Z",
          "shell.execute_reply": "2025-03-15T07:25:25.638659Z"
        },
        "id": "8c9U8C9oSlVJ"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wandb is used here to monitor training. You'll need to create account and get token to use it."
      ],
      "metadata": {
        "id": "uzBjvP0T1S0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import os\n",
        "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
        "\n",
        "wandb.login(key=wb_token)\n",
        "run = wandb.init(\n",
        "    project='Fine-tune-DeepSeek-R1-Distill-Llama-8B on South Ostrobotnia dialect 2',\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T07:25:25.640609Z",
          "iopub.execute_input": "2025-03-15T07:25:25.640838Z",
          "iopub.status.idle": "2025-03-15T07:25:40.059852Z",
          "shell.execute_reply.started": "2025-03-15T07:25:25.640818Z",
          "shell.execute_reply": "2025-03-15T07:25:40.059023Z"
        },
        "id": "RHuN_n8HSlVK"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Seek model is downloaded from Huggingface. You'll need Huggingface api key for this."
      ],
      "metadata": {
        "id": "LEKl3h3Sy3ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = hf_token,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T07:25:40.061016Z",
          "iopub.execute_input": "2025-03-15T07:25:40.061335Z",
          "iopub.status.idle": "2025-03-15T07:26:48.153053Z",
          "shell.execute_reply.started": "2025-03-15T07:25:40.061312Z",
          "shell.execute_reply": "2025-03-15T07:26:48.152432Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfcJ0NfGSlVL",
        "outputId": "57f6e2df-a039-4e42-a6e7-3a4304ed1b01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.3.17: Fast Llama patching. Transformers: 4.48.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt for testing with standard Finnish how that translates to the dialect."
      ],
      "metadata": {
        "id": "KfXlhJc8zMs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "Translate standard Finnish sentence to South Ostrobothnian dialect.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "<think>{}\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T07:26:48.153880Z",
          "iopub.execute_input": "2025-03-15T07:26:48.154083Z",
          "iopub.status.idle": "2025-03-15T07:26:48.158203Z",
          "shell.execute_reply.started": "2025-03-15T07:26:48.154065Z",
          "shell.execute_reply": "2025-03-15T07:26:48.157412Z"
        },
        "id": "RbrLUXQISlVL"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run test on the original model before finetuning."
      ],
      "metadata": {
        "id": "2j6mcjGBzacW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "standard_finnish = \"Hevoskauppias ajoi uudella hevosellaan meid√§n talon ohi. Katsoin h√§nt√§ aitan ovelta.\"\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "inputs = tokenizer([prompt_style.format(standard_finnish, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids=inputs.input_ids,\n",
        "    attention_mask=inputs.attention_mask,\n",
        "    max_new_tokens=1200,\n",
        "    use_cache=True,\n",
        ")\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "print(\"Dialect:\")\n",
        "print(response[0].split(\"### Response:\")[1])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T07:26:48.159087Z",
          "iopub.execute_input": "2025-03-15T07:26:48.159374Z",
          "iopub.status.idle": "2025-03-15T07:27:14.274869Z",
          "shell.execute_reply.started": "2025-03-15T07:26:48.159352Z",
          "shell.execute_reply": "2025-03-15T07:27:14.274072Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BddXNWJSlVN",
        "outputId": "cf5491e1-9792-4d56-af3a-9f5afc907c65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialect:\n",
            "\n",
            "<think>\n",
            "Okay, so I have this task where I need to translate a standard Finnish sentence into the South Ostrobothnian dialect. Let me break this down step by step. First, I need to understand the original sentence and then figure out how it would be expressed in the dialect.\n",
            "\n",
            "The original sentence is: \"Hevoskauppias ajoi uudella hevosellaan meid√§n talon ohi. Katsoin h√§nt√§ aitan ovelta.\"\n",
            "\n",
            "Alright, let's parse this sentence. The first part is \"Hevoskauppias ajoi uudella hevosellaan meid√§n talon ohi.\" This seems to be about a horse dealer who is driving a new horse past their house. The second part is \"Katsoin h√§nt√§ aitan ovelta,\" which translates to \"I watched him from the window.\"\n",
            "\n",
            "Now, translating this into South Ostrobothnian dialect. I know that dialects often have unique words and structures compared to standard language. So, I need to identify the key components and see how they might be expressed differently.\n",
            "\n",
            "Starting with \"Hevoskauppias.\" In the dialect, I think \"kauppias\" might be a term of endearment or a nickname, so perhaps it would be \"Hevosen kauppias\" or something similar, but I'm not sure. Maybe it's just \"Hevoskauppias\" as is.\n",
            "\n",
            "Next, \"ajoi uudella hevosellaan.\" \"Ajoi\" means \"drove\" or \"drove away.\" \"Uudella\" is \"new,\" and \"hevosellaan\" is \"with the new horse.\" So, in dialect, maybe \"ajoi uudella hevosellaan\" could be \"ajoi uudell' hevosellaan,\" with an apostrophe for the \"j\" sound.\n",
            "\n",
            "Then, \"meid√§n talon ohi.\" \"Meid√§n\" is \"our,\" \"talon\" is \"house,\" and \"ohi\" is \"by\" or \"near.\" In dialect, \"talon ohi\" might be \"talon ohi,\" but perhaps \"meid√§n talon ohi\" could be simplified or have a different structure.\n",
            "\n",
            "The second sentence, \"Katsoin h√§nt√§ aitan ovelta,\" translates to \"I watched him from the window.\" In dialect, \"aivan ovelta\" might become \"aivan ovelta,\" but perhaps \"aivan\" is used differently. Maybe \"aivan ovelta\" is the same, but \"h√§nt√§\" is just \"him.\"\n",
            "\n",
            "Putting it all together, the translated sentence might be:\n",
            "\n",
            "\"Hevoskauppias ajoi uudell' hevosellaan meid√§n talon ohi. Katsoin h√§nt√§ aivan ovelta.\"\n",
            "\n",
            "I think that's a reasonable attempt. I might have missed some nuances, but this seems to capture the essence of the original sentence in the dialect.\n",
            "</think>\n",
            "\n",
            "Hevoskauppias ajoi uudell' hevosellaan meid√§n talon ohi. Katsoin h√§nt√§ aivan ovelta.\n",
            "\n",
            "---\n",
            "\n",
            "### Translation:\n",
            "The horse dealer drove the new horse past our house. I watched him from the window.<ÔΩúend‚ñÅof‚ñÅsentenceÔΩú>\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training prompt for standard Finnish and dialect sentence pairs."
      ],
      "metadata": {
        "id": "etmh2N30zumu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "Translate standard Finnish sentence to South Ostrobothnian dialect.\n",
        "\n",
        "### Question:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "<think>\n",
        "{}\n",
        "</think>\n",
        "{}\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T07:27:14.275729Z",
          "iopub.execute_input": "2025-03-15T07:27:14.276003Z",
          "iopub.status.idle": "2025-03-15T07:27:14.280362Z",
          "shell.execute_reply.started": "2025-03-15T07:27:14.275980Z",
          "shell.execute_reply": "2025-03-15T07:27:14.279462Z"
        },
        "id": "zfwfPSYTSlVN"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training prompt for standard Finnish to dialect vocabulary."
      ],
      "metadata": {
        "id": "LKCCZtvszz4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_prompt_vocabulary_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
        "Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "Translate the following word from standard Finnish to South Ostrobothnian dialect.\n",
        "\n",
        "### Word:\n",
        "{}\n",
        "\n",
        "### Dialect Equivalent:\n",
        "<think>\n",
        "{}\n",
        "</think>\n",
        "{}\"\"\""
      ],
      "metadata": {
        "id": "ve2t9bAc9jHf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formatting function for standard Finnish to dialect sentence pairs."
      ],
      "metadata": {
        "id": "33RVEZyu0B9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
        "\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    inputs = examples[\"Question\"]\n",
        "    cots = examples[\"Complex_CoT\"]\n",
        "    outputs = examples[\"Response\"]\n",
        "    texts = []\n",
        "    for input, cot, output in zip(inputs, cots, outputs):\n",
        "        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return {\n",
        "        \"text\": texts,\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T07:27:14.282413Z",
          "iopub.execute_input": "2025-03-15T07:27:14.282686Z",
          "iopub.status.idle": "2025-03-15T07:27:14.297201Z",
          "shell.execute_reply.started": "2025-03-15T07:27:14.282658Z",
          "shell.execute_reply": "2025-03-15T07:27:14.296527Z"
        },
        "id": "uwjS6ZQHSlVO"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formatting function for vocabulary prompts."
      ],
      "metadata": {
        "id": "MUbQ-5dY0KZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_prompts_vocab_func(examples):\n",
        "    inputs = examples[\"Question\"]\n",
        "    cots = examples[\"Complex_CoT\"]\n",
        "    outputs = examples[\"Response\"]\n",
        "    texts = []\n",
        "    for input, cot, output in zip(inputs, cots, outputs):\n",
        "        text = train_prompt_vocabulary_style.format(input, cot, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return {\n",
        "        \"text\": texts,\n",
        "    }"
      ],
      "metadata": {
        "id": "qQmt7wJHMbK1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to get Pekka Pohjanp√§√§'s blog. The blog is split into sentence level and arranged as list of dictionaries."
      ],
      "metadata": {
        "id": "00B4K5cP0O7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "def get_pohopekka():\n",
        "    main_page_link=\"http://pohopekka.blogspot.com/\"\n",
        "    structured_data = []\n",
        "    page=requests.get(main_page_link)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    for element in soup.find_all([\"h2\", \"div\"]):\n",
        "        if element.name==\"h2\":\n",
        "            latest_h2 = element.text.strip()\n",
        "        elif element.name==\"div\" and \"blogPost\" in element.get(\"class\", []):\n",
        "            if latest_h2:\n",
        "                content=element.text.split(\"# posted\")[0].strip().replace('\\r',' ').replace('PEKAN SIVUPERSOONA','').\\\n",
        "                    replace('Pekan Sivupersoona','').replace(\"\\n\",\" \")\n",
        "\n",
        "                content=content.split(\"----\",1)[0].strip()\n",
        "\n",
        "                if len(content)>5:\n",
        "                    structured_data.append({\"title\": latest_h2, \"content\": content})\n",
        "                latest_h2 = None\n",
        "\n",
        "    return structured_data"
      ],
      "metadata": {
        "id": "NVx-SiWNmlX8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matching Pekka Pohjanp√§√§'s story on dialect to standard Finnish based on precalculated index."
      ],
      "metadata": {
        "id": "6kV_BPIi0k0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match_story_sentences_to_standard(stories,standard_finnish_sentences):\n",
        "    story_idx=0\n",
        "    dialect=dict()\n",
        "    for story_ in stories:\n",
        "        story=story_[\"content\"]\n",
        "        story_splitted=story.split(\". \")\n",
        "        inside_story_idx=0\n",
        "        for sentence in story_splitted:\n",
        "            dialect[str(story_idx) + \"-\" + str(inside_story_idx)] = sentence\n",
        "            inside_story_idx+=1\n",
        "        story_idx+=1\n",
        "\n",
        "\n",
        "    with open(standard_finnish_sentences) as f:\n",
        "        standard=json.load(f)\n",
        "\n",
        "    standard_dialect=[]\n",
        "\n",
        "    for key in standard:\n",
        "        standard_dialect.append({\"standard\":standard[key],\"dialect\":dialect[key]})\n",
        "    return standard_dialect"
      ],
      "metadata": {
        "id": "Qyac9aa7mnox"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to compose standard dialect prompts."
      ],
      "metadata": {
        "id": "z7l0raBc1XAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_translated(standard_dialect):\n",
        "    data_arr=[]\n",
        "    for data in standard_dialect:\n",
        "        target_data=data[\"dialect\"].strip()\n",
        "        input_data=data[\"standard\"].strip()\n",
        "        system_dict=dict()\n",
        "        input_dict=dict()\n",
        "        target_dict=dict()\n",
        "        system_dict[\"role\"] = \"system\"\n",
        "        system_dict[\"content\"]=\"You translate standard Finnish sentences into the South Ostrobothnian dialect.\"\n",
        "        input_dict[\"role\"] = \"user\"\n",
        "        input_dict[\"content\"] = \"Ilmaise seuraava Etel√§-Pohjanmaan murteella: \" + input_data\n",
        "\n",
        "        target_dict[\"role\"] = \"assistant\"\n",
        "        target_dict[\"content\"] = target_data\n",
        "        data_arr.append({\n",
        "            \"Question\": input_data,  # Standard Finnish\n",
        "            \"Complex_CoT\": \"\",\n",
        "            \"Response\": target_data,  # South Ostrobothnian dialect\n",
        "            \"text\": input_data + \" - \" + target_data  # Same as Question and Response\n",
        "        })\n",
        "\n",
        "\n",
        "    return data_arr"
      ],
      "metadata": {
        "id": "zMrYwxwsm20y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stories=get_pohopekka()\n",
        "standard_dialect=match_story_sentences_to_standard(stories=stories,standard_finnish_sentences=DATA_DIR+\"/standard_finnish_sentences.json\")\n",
        "train_set=write_translated(standard_dialect=standard_dialect)\n",
        "random.shuffle(train_set)"
      ],
      "metadata": {
        "id": "xasgcCLqm8OJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run standard Finnish vs. dialect data generation."
      ],
      "metadata": {
        "id": "Pv5oRm3r1pLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "dataset0 = Dataset.from_list(train_set)\n",
        "\n",
        "dataset0 = dataset0.map(formatting_prompts_func, batched = True,)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T07:27:14.298412Z",
          "iopub.execute_input": "2025-03-15T07:27:14.298697Z",
          "iopub.status.idle": "2025-03-15T07:27:19.550058Z",
          "shell.execute_reply.started": "2025-03-15T07:27:14.298667Z",
          "shell.execute_reply": "2025-03-15T07:27:19.549158Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8927e13b17a54352a84f62e23681ce1c",
            "21197ff61a2a41608ec22e1c5a652a58",
            "aa0d03affee44739a7254fa4942656bb",
            "31c32434249749139d029f184576f0c7",
            "2f1bee6cb65c4d8482a626f225074501",
            "5e5f1b63655a4ec7b479f4634067cdd3",
            "5b877b99c03f44659ec8ad6079d07801",
            "b944732af3004ccfaef4a2691cd82495",
            "036eac72cb4944dda654d0c5eb0993b5",
            "ed89eb8130784397903a65fa0b6da84e",
            "cd831f04378f4eb1be9ce2b7c3047f86"
          ]
        },
        "id": "2RrXytIuSlVO",
        "outputId": "294ad53f-5323-4096-c73c-6e7793911201"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/306 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8927e13b17a54352a84f62e23681ce1c"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the vocabulary data, which I'm sharing in the repo."
      ],
      "metadata": {
        "id": "HJmw_UCA1tVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file_path = DATA_DIR+'/vocabulary_deep_seek_format.json'\n",
        "\n",
        "\n",
        "dataset1 = load_dataset('json',data_files=data_file_path, split = \"train[:-1]\",trust_remote_code=True)\n",
        "\n",
        "dataset1 = dataset1.map(formatting_prompts_vocab_func, batched = True,)"
      ],
      "metadata": {
        "id": "QuiMNAZo_Ph7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model configurations."
      ],
      "metadata": {
        "id": "AfnwuNDZ15hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n",
        "    random_state=3407,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T07:27:19.551116Z",
          "iopub.execute_input": "2025-03-15T07:27:19.551444Z",
          "iopub.status.idle": "2025-03-15T07:27:25.644607Z",
          "shell.execute_reply.started": "2025-03-15T07:27:19.551411Z",
          "shell.execute_reply": "2025-03-15T07:27:25.643691Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3QlpPb4SlVP",
        "outputId": "18af28fc-cd59-44a7-d58a-52a610dba49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.3.17 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainer for standard Finnish - dialect sentence pairs."
      ],
      "metadata": {
        "id": "N-6oyi-91-wN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer_transl = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset0,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        # Use num_train_epochs = 1, warmup_ratio for full training runs!\n",
        "        warmup_steps=5,\n",
        "        #max_steps=60,\n",
        "        num_train_epochs=3,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=10,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T07:27:25.645541Z",
          "iopub.execute_input": "2025-03-15T07:27:25.645792Z",
          "iopub.status.idle": "2025-03-15T07:27:28.297562Z",
          "shell.execute_reply.started": "2025-03-15T07:27:25.645770Z",
          "shell.execute_reply": "2025-03-15T07:27:28.296498Z"
        },
        "id": "iZ63LanwSlVQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9e6ee0b6599d47d8b97bd05426328951",
            "fd19162a2ebe4e3f83302e84925a4dd3",
            "524d72b59bb54fa0b9637744205f3a11",
            "ef700c51b4474237a79c9d2caaac6cc3",
            "81ca3194b6b9434e913210e8100af975",
            "1acfd56ea16c4e68977494991b4f949b",
            "bd699d3d83e14b8f8529370807169f05",
            "1db372d15294400cb7442d6500ce1d2c",
            "1f201bf1c46d4e639eba748ab8e0870f",
            "8bf0d8e012ef42cf844c8b633964aef6",
            "dcf65fa8af5d4673ab201fee64f01068"
          ]
        },
        "outputId": "de43b916-3833-469e-f284-b1e566ccbbf4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/306 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e6ee0b6599d47d8b97bd05426328951"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainer for vocabulary data. Less epochs and smaller learning rate as number of training samples is larger than number of samples on the sentence pair data."
      ],
      "metadata": {
        "id": "wP6vCXvO2EDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#works when not ran\n",
        "trainer_vocab = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset1,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        # Use num_train_epochs = 1, warmup_ratio for full training runs!\n",
        "        warmup_steps=5,\n",
        "        #max_steps=60,\n",
        "        num_train_epochs=1,\n",
        "        learning_rate=5e-5,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=10,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs/vocab\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "7iTXNTcxTGeM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run trainers."
      ],
      "metadata": {
        "id": "cDGVGX6j2Vsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "trainer_stats = trainer_transl.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T07:27:28.298472Z",
          "iopub.execute_input": "2025-03-15T07:27:28.298742Z",
          "iopub.status.idle": "2025-03-15T08:12:04.935861Z",
          "shell.execute_reply.started": "2025-03-15T07:27:28.298715Z",
          "shell.execute_reply": "2025-03-15T08:12:04.935157Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "b1OIazATSlVQ",
        "outputId": "9fdc07f0-0d6b-4591-825a-1896a10d8543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 19 20:06:32 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0             32W /   70W |    6242MiB /  15360MiB |      4%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 306 | Num Epochs = 3 | Total steps = 114\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [114/114 10:01, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.245500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.858500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.591100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.441700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.133700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.120400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.041800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.972400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.729300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.780500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.711700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "trainer_stats = trainer_vocab.train()"
      ],
      "metadata": {
        "id": "2itzLVVWUSgW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a7e879e-b938-43a7-bdb2-43e20c94833f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 19 20:16:42 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0             33W /   70W |    7012MiB /  15360MiB |      3%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 1,688 | Num Epochs = 1 | Total steps = 211\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='211' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [211/211 14:18, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.236000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.363900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.321300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.325500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.322900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.340200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.329000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.336000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.321800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.297000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.308600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.298700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.302900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.288300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.319500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.306900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.324000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.306500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.281500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.287000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.299700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run test on signle sentence."
      ],
      "metadata": {
        "id": "l0BRv1et2YaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "standard_finnish = \"Hevoskauppias ajoi uudella hevosellaan meid√§n talon ohi. Katsoin h√§nt√§ aitan ovelta.\"\n",
        "\n",
        "\n",
        "FastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n",
        "inputs = tokenizer([prompt_style.format(standard_finnish, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids=inputs.input_ids,\n",
        "    attention_mask=inputs.attention_mask,\n",
        "    max_new_tokens=1200,\n",
        "    use_cache=True,\n",
        ")\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "print(\"Dialect:\")\n",
        "print(response[0].split(\"### Response:\")[1])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-15T08:12:04.936884Z",
          "iopub.execute_input": "2025-03-15T08:12:04.937104Z",
          "iopub.status.idle": "2025-03-15T08:12:32.743352Z",
          "shell.execute_reply.started": "2025-03-15T08:12:04.937085Z",
          "shell.execute_reply": "2025-03-15T08:12:32.742274Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQtRFraISlVR",
        "outputId": "0618ff47-1805-4bdb-dc67-f42048fa89fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialect:\n",
            "\n",
            "<think>\n",
            "\n",
            "</think>\n",
            "Hevooskauppias ajoo uureella hevoosella, meir√§n talo ohi, kattoon sit√§ aita ovelta<ÔΩúend‚ñÅof‚ñÅsentenceÔΩú>\n"
          ]
        }
      ],
      "execution_count": 27
    }
  ]
}